{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub\n",
    "# !pip install git+https://github.com/openai/whisper.git\n",
    "# !pip install srt\n",
    "# !pip install -U yt-dlp\n",
    "# !pip install   pyannote.audio\n",
    "# !pip install huggingface-hub\n",
    "# !pip install -U webvtt-py\n",
    "# !pip install -q onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo y| conda install -c conda-forge ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7cfb2d",
   "metadata": {},
   "source": [
    "# 各種パラメーター設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c17ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:00:52.131140Z",
     "start_time": "2022-11-17T11:00:52.125961Z"
    }
   },
   "outputs": [],
   "source": [
    "target_id=\"shogi\"\n",
    "spacermilli = 0\n",
    "rawdata_folder_path = \"\"\n",
    "analysis_folder_path = \"\"\n",
    "rawdata_path = rawdata_folder_path+target_id+\".wav\"\n",
    "save_text_path = analysis_folder_path+target_id+\"_音声認識_whisper_with_vad.txt\"\n",
    "save_text_path0 = analysis_folder_path+target_id+\"speaker0_音声認識_whisper_with_vad.txt\"\n",
    "save_text_path1 = analysis_folder_path+target_id+\"speaker1_音声認識_whisper_with_vad.txt\"\n",
    "save_srt_path = analysis_folder_path+target_id+\"_音声認識_whisper_with_vad.srt\"\n",
    "#人の声が入っているかどうかを識別するパラメーター。　オーディオチャンク毎に確率が出る。デフォルトは0.5\n",
    "vad_threshold=0.4\n",
    "# 音声ファイルを分割するための閾値。大きくすればするほど、一つのファイルに複数の音声が入る。\n",
    "#whisperの処理性能的にある程度長めの音声で判定しているので、一つのファイルに複数の音声を詰め込むと処理性能が落ちる？\n",
    "#要実験\n",
    "chunk_threshold = 2\n",
    "#音声に対する感度を少し下げる（このワードを検知したら無視する可能性が高い）\n",
    "suppress_low = [\n",
    "    \"視聴\",\n",
    "    \"ご視聴\",\n",
    "]\n",
    "#音声に対する感度を大きく下げる\n",
    "suppress_high = [\n",
    "    \"ご視聴\",\n",
    "    \"視聴ありがとうございました\",\n",
    "    \"ご視聴ありがとうございました!\"\n",
    "    \"私はあなたを愛しています。\"\n",
    "]\n",
    "#音声に対する感度を大きく上げる\n",
    "promotion_high = [,]\n",
    "#whisperの試行回数\n",
    "max_attempts=1\n",
    "#whisperモデルで無音判定する閾値。高いほど1.0に近づくほど無音の可能性が高い。デフォルトは0.6\n",
    "no_speech_threshold= 0.7\n",
    "#whisperモデルで喋り声の判定する閾値。高いほど喋っている可能性が高い。デフォルト-1.0\n",
    "avg_logprob = -1.0\n",
    "# vad(voice acitivity detectorモデルのインストール)\n",
    "SAMPLING_RATE = 16000\n",
    "speakers_num=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55bf4b",
   "metadata": {},
   "source": [
    "# インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8cac919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:00:55.144706Z",
     "start_time": "2022-11-17T11:00:52.132192Z"
    }
   },
   "outputs": [],
   "source": [
    "from srt import Subtitle\n",
    "from pydub import AudioSegment\n",
    "import srt\n",
    "import whisper\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import whisper\n",
    "import os\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import torch\n",
    "from pyannote.audio import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf2f488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0207d31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (!aws).\n",
      "Your token has been saved to /home/ec2-user/.huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1585e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:01:10.508126Z",
     "start_time": "2022-11-17T11:01:04.887280Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /home/ec2-user/.cache/torch/hub/master.zip\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(1)\n",
    "\n",
    "USE_ONNX = False \n",
    "model_vad, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                                  model='silero_vad',\n",
    "                                  force_reload=True,\n",
    "                                  onnx=USE_ONNX)\n",
    "\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee436a0",
   "metadata": {},
   "source": [
    "# pyannoteによる話者分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8af34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained('pyannote/speaker-diarization', use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4e50f2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:01:15.132740Z",
     "start_time": "2022-11-17T11:01:10.509127Z"
    }
   },
   "outputs": [],
   "source": [
    "dz = pipeline(rawdata_path, num_speakers=speakers_num)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43ae5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(target_id+\"_diarization.txt\", \"w\") as text_file:\n",
    "    text_file.write(str(dz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18738432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def millisec(timeStr):\n",
    "  spl = timeStr.split(\":\")\n",
    "  s = (int)((int(spl[0]) * 60 * 60 + int(spl[1]) * 60 + float(spl[2]) )* 1000)\n",
    "  return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5a8d0",
   "metadata": {},
   "source": [
    "# vadによる話し声の有無判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eea04bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:14:54.729450Z",
     "start_time": "2022-11-17T11:01:15.133852Z"
    }
   },
   "outputs": [],
   "source": [
    "#タイムスタンプの作成\n",
    "sound_val = read_audio(rawdata_path, sampling_rate=SAMPLING_RATE)\n",
    "speech_timestamps = get_speech_timestamps(sound_val, model_vad, sampling_rate=SAMPLING_RATE, threshold=vad_threshold)\n",
    "#pprint(speech_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0209b958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:14:54.739709Z",
     "start_time": "2022-11-17T11:14:54.732754Z"
    }
   },
   "outputs": [],
   "source": [
    "# 声の間がchunk_thresholdよりも長かったら音声ファイルを複数に分割する様にする。\n",
    "u = [[]]\n",
    "for i in range(len(speech_timestamps)):\n",
    "    if i > 0 and speech_timestamps[i][\"start\"] > speech_timestamps[i - 1][\"end\"] + (chunk_threshold * SAMPLING_RATE):\n",
    "        u.append([])\n",
    "    u[-1].append(speech_timestamps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b878d0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:14:55.318368Z",
     "start_time": "2022-11-17T11:14:54.740840Z"
    }
   },
   "outputs": [],
   "source": [
    "# 人の声が入っている部分だけを抽出。\n",
    "#処理時間を短縮することができる\n",
    "for i in range(len(u)):\n",
    "    save_audio(\"vad_chunks_\" + str(i) + \".wav\",\n",
    "               collect_chunks(u[i], sound_val),\n",
    "               sampling_rate=SAMPLING_RATE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f27a63ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:14:55.329211Z",
     "start_time": "2022-11-17T11:14:55.319379Z"
    }
   },
   "outputs": [],
   "source": [
    "# タイムスタンプを秒に変換\n",
    "for i in range(len(u)):\n",
    "    time = 0.0\n",
    "    offset = 0.0\n",
    "    for j in range(len(u[i])):\n",
    "        u[i][j][\"start\"] /= SAMPLING_RATE\n",
    "        u[i][j][\"end\"] /= SAMPLING_RATE\n",
    "        u[i][j][\"chunk_start\"] = time\n",
    "        time += u[i][j][\"end\"] - u[i][j][\"start\"]\n",
    "        u[i][j][\"chunk_end\"] = time\n",
    "        if j == 0:\n",
    "            offset += u[i][j][\"start\"]\n",
    "        else:\n",
    "            offset += u[i][j][\"start\"] - u[i][j - 1][\"end\"]\n",
    "        u[i][j][\"offset\"] = offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e701e70",
   "metadata": {},
   "source": [
    "# whisperによる音声解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f48b9f19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T11:15:07.596292Z",
     "start_time": "2022-11-17T11:14:55.334236Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.87G/2.87G [00:44<00:00, 69.9MiB/s]\n"
     ]
    }
   ],
   "source": [
    "mode_whisperl = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad69c2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T16:16:42.748961Z",
     "start_time": "2022-11-17T11:15:07.604052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/139620 [00:00<?, ?frames/s]\u001b[A\n",
      "  2%|▏         | 2598/139620 [00:05<05:04, 449.74frames/s]\u001b[A\n",
      "  4%|▍         | 5258/139620 [00:11<05:03, 442.69frames/s]\u001b[A\n",
      "  6%|▌         | 8248/139620 [00:18<04:45, 460.18frames/s]\u001b[A\n",
      "  8%|▊         | 10698/139620 [00:23<04:43, 453.96frames/s]\u001b[A\n",
      " 10%|▉         | 13438/139620 [00:28<04:25, 475.44frames/s]\u001b[A\n",
      " 12%|█▏        | 16158/139620 [00:34<04:17, 480.34frames/s]\u001b[A\n",
      " 14%|█▎        | 19118/139620 [00:38<03:47, 529.06frames/s]\u001b[A\n",
      " 16%|█▌        | 21818/139620 [00:44<03:43, 526.28frames/s]\u001b[A\n",
      " 18%|█▊        | 24618/139620 [00:50<03:49, 500.34frames/s]\u001b[A\n",
      " 20%|█▉        | 27318/139620 [00:57<04:06, 455.01frames/s]\u001b[A\n",
      " 22%|██▏       | 30118/139620 [01:03<04:01, 453.28frames/s]\u001b[A\n",
      " 24%|██▎       | 32918/139620 [01:08<03:34, 497.17frames/s]\u001b[A\n",
      " 26%|██▌       | 35818/139620 [01:13<03:25, 505.88frames/s]\u001b[A\n",
      " 28%|██▊       | 38618/139620 [01:19<03:22, 498.23frames/s]\u001b[A\n",
      " 30%|██▉       | 41518/139620 [01:25<03:21, 487.69frames/s]\u001b[A\n",
      " 32%|███▏      | 44118/139620 [01:31<03:17, 484.15frames/s]\u001b[A\n",
      " 34%|███▎      | 47018/139620 [01:37<03:16, 470.75frames/s]\u001b[A\n",
      " 36%|███▌      | 49718/139620 [01:43<03:15, 459.72frames/s]\u001b[A\n",
      " 38%|███▊      | 52518/139620 [01:49<03:05, 470.33frames/s]\u001b[A\n",
      " 40%|███▉      | 55218/139620 [01:55<03:03, 459.23frames/s]\u001b[A\n",
      " 41%|████▏     | 57918/139620 [02:02<03:02, 446.76frames/s]\u001b[A\n",
      " 43%|████▎     | 60418/139620 [02:07<02:57, 447.30frames/s]\u001b[A\n",
      " 45%|████▌     | 62918/139620 [02:13<02:49, 452.18frames/s]\u001b[A\n",
      " 47%|████▋     | 65818/139620 [02:20<02:48, 437.58frames/s]\u001b[A\n",
      " 49%|████▉     | 68618/139620 [02:26<02:41, 439.36frames/s]\u001b[A\n",
      " 51%|█████     | 71418/139620 [02:31<02:27, 462.82frames/s]\u001b[A\n",
      " 53%|█████▎    | 74118/139620 [02:37<02:17, 476.07frames/s]\u001b[A\n",
      " 55%|█████▍    | 76718/139620 [02:42<02:10, 482.40frames/s]\u001b[A\n",
      " 57%|█████▋    | 79618/139620 [02:49<02:09, 464.93frames/s]\u001b[A\n",
      " 59%|█████▉    | 82218/139620 [02:54<02:02, 469.87frames/s]\u001b[A\n",
      " 61%|██████    | 84918/139620 [03:00<01:58, 462.97frames/s]\u001b[A\n",
      " 63%|██████▎   | 87718/139620 [03:06<01:49, 474.04frames/s]\u001b[A\n",
      " 65%|██████▍   | 90618/139620 [03:12<01:44, 467.51frames/s]\u001b[A\n",
      " 67%|██████▋   | 93318/139620 [03:18<01:39, 464.14frames/s]\u001b[A\n",
      " 69%|██████▊   | 95818/139620 [03:23<01:33, 470.98frames/s]\u001b[A\n",
      " 71%|███████   | 98518/139620 [03:28<01:22, 498.97frames/s]\u001b[A\n",
      " 73%|███████▎  | 101318/139620 [03:33<01:13, 520.97frames/s]\u001b[A\n",
      " 75%|███████▍  | 104218/139620 [03:39<01:11, 493.98frames/s]\u001b[A\n",
      " 77%|███████▋  | 107018/139620 [03:46<01:10, 465.13frames/s]\u001b[A\n",
      " 79%|███████▊  | 109818/139620 [03:51<01:01, 484.55frames/s]\u001b[A\n",
      " 81%|████████  | 112618/139620 [03:56<00:53, 508.11frames/s]\u001b[A\n",
      " 83%|████████▎ | 115318/139620 [04:01<00:46, 518.37frames/s]\u001b[A\n",
      " 85%|████████▍ | 118118/139620 [04:07<00:42, 508.95frames/s]\u001b[A\n",
      " 87%|████████▋ | 120918/139620 [04:14<00:39, 471.51frames/s]\u001b[A\n",
      " 88%|████████▊ | 123518/139620 [04:20<00:35, 450.45frames/s]\u001b[A\n",
      " 90%|█████████ | 126218/139620 [04:25<00:27, 480.51frames/s]\u001b[A\n",
      " 92%|█████████▏| 129118/139620 [04:31<00:21, 478.95frames/s]\u001b[A\n",
      " 95%|█████████▍| 132018/139620 [04:37<00:16, 474.95frames/s]\u001b[A\n",
      " 97%|█████████▋| 134918/139620 [04:43<00:09, 471.43frames/s]\u001b[A\n",
      " 99%|█████████▊| 137618/139620 [04:51<00:04, 439.13frames/s]\u001b[A\n",
      "100%|█████████▉| 139218/139620 [04:55<00:00, 424.86frames/s]\u001b[A\n",
      "100%|██████████| 139620/139620 [04:56<00:00, 471.53frames/s]\u001b[A\n",
      "100%|██████████| 1/1 [04:57<00:00, 297.54s/it]\n"
     ]
    }
   ],
   "source": [
    "test_counter =0\n",
    "subs = []\n",
    "subs_text = []\n",
    "segment_info = []\n",
    "sub_index = 1\n",
    "for i in tqdm(range(len(u))):\n",
    "    line_buffer = []  # Used for DeepL\n",
    "    for x in range(max_attempts):\n",
    "        result = mode_whisperl.transcribe(\n",
    "            \"vad_chunks_\" + str(i) + \".wav\", \n",
    "            verbose=False, language=\"ja\",\n",
    "            no_speech_threshold=no_speech_threshold,temperature=0.2,\n",
    "        logprob_threshold=avg_logprob)\n",
    "        # Break if result doesn't end with severe hallucinations\n",
    "        if len(result[\"segments\"]) == 0:\n",
    "            break\n",
    "        elif result[\"segments\"][-1][\"end\"] < u[i][-1][\"chunk_end\"] + 10.0:\n",
    "            break\n",
    "        elif x+1 < max_attempts:\n",
    "            print(\"Retrying chunk\", i)\n",
    "    for r in result[\"segments\"]:\n",
    "        # Skip audio timestamped after the chunk has ended\n",
    "        if r[\"start\"] > u[i][-1][\"chunk_end\"]:\n",
    "            continue\n",
    "        # 特定のワード、フレーズに対して感度を調整\n",
    "        for s in suppress_low:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.30\n",
    "        for s in suppress_high:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] -= 0.50\n",
    "        for s in promotion_high:\n",
    "            if s in r[\"text\"]:\n",
    "                r[\"avg_logprob\"] += 0.20\n",
    "         # Keep segment info for debugging\n",
    "        del r[\"tokens\"]\n",
    "        segment_info.append(r)\n",
    "        if r[\"avg_logprob\"] < avg_logprob or r[\"no_speech_prob\"] > no_speech_threshold:\n",
    "            #print(\"do_skip\")\n",
    "            continue\n",
    "        # セグメント情報を保持\n",
    "        segment_info.append(r)\n",
    "        # Set start timestamp\n",
    "        start = r[\"start\"] + u[i][0][\"offset\"]\n",
    "        for j in range(len(u[i])):\n",
    "            if (\n",
    "                r[\"start\"] >= u[i][j][\"chunk_start\"]\n",
    "                and r[\"start\"] <= u[i][j][\"chunk_end\"]\n",
    "            ):\n",
    "                start = r[\"start\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # subsの重複を避ける\n",
    "        if len(subs) > 0:\n",
    "            last_end = datetime.timedelta.total_seconds(subs[-1].end)\n",
    "            if last_end > start:\n",
    "                subs[-1].end = datetime.timedelta(seconds=start)\n",
    "        # タイムスタンプの終わりを判定\n",
    "        end = u[i][-1][\"end\"] + 0.5\n",
    "        for j in range(len(u[i])):\n",
    "            if r[\"end\"] >= u[i][j][\"chunk_start\"] and r[\"end\"] <= u[i][j][\"chunk_end\"]:\n",
    "                end = r[\"end\"] + u[i][j][\"offset\"]\n",
    "                break\n",
    "        # Add to SRT list\n",
    "        subs.append(\n",
    "            srt.Subtitle(\n",
    "                index=sub_index,\n",
    "                start=datetime.timedelta(seconds=start),\n",
    "                end=datetime.timedelta(seconds=end),\n",
    "                content=r[\"text\"].strip(),\n",
    "            )\n",
    "        )\n",
    "        subs_text.append(r[\"text\"].strip())\n",
    "        sub_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d1b5d",
   "metadata": {},
   "source": [
    "# whisperとpyaanoteの統合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bc1a4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "処理が完了しました。\n",
      "471\n",
      "処理が完了しました。\n"
     ]
    }
   ],
   "source": [
    "#話者分類\n",
    "speaker_zero = []\n",
    "speaker_one= []\n",
    "counter=0\n",
    "#話はじめがpyaanoteにより分類された話時間の内のどちらに含まれるかで分類\n",
    "#厳密にやるならwhisper文字起こしの解析結果がpyaanoteで解析された話時間のどちらが長いか判定すれば良い\n",
    "for i in range(len(dzs)):\n",
    "    end_time = datetime.timedelta(hours= float(dzs[i][20:22]),\n",
    "                   minutes=float(dzs[i][23:25]),seconds=float(dzs[i][26:32]))\n",
    "    try:\n",
    "        if dzs[i][-10:]==\"SPEAKER_00\":\n",
    "            while subs[counter].start < end_time:\n",
    "                speaker_zero.append(subs[counter].content.strip())\n",
    "                counter += 1\n",
    "                #print(i,counter,\"SPEAKER_00\")\n",
    "        if dzs[i][-10:]==\"SPEAKER_01\":\n",
    "            while subs[counter].start < end_time:\n",
    "                speaker_one.append(subs[counter].content.strip())\n",
    "                counter += 1\n",
    "    except IndexError:\n",
    "        print(counter)\n",
    "        print('処理が完了しました。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ac74d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#srtファイルの作成\n",
    "with open(save_srt_path, \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(srt.compose(subs))\n",
    "#textファイルの作成\n",
    "with open(save_text_path, \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(''.join(subs_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c542ad2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-17T16:16:42.766206Z",
     "start_time": "2022-11-17T16:16:42.752481Z"
    }
   },
   "outputs": [],
   "source": [
    "# pyaanoteによる話者分離結果を記載\n",
    "with open(\"diarization.txt\", \"w\") as text_file:\n",
    "    text_file.write(str(dz))\n",
    "#話者1のファイルの作成\n",
    "with open(save_text_path0, \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(''.join(speaker_zero))\n",
    "#話者1のファイルの作成    \n",
    "with open(save_text_path1, \"w\", encoding=\"utf8\") as f:\n",
    "    f.write(''.join(speaker_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in range(len(u)):\n",
    "        os.remove(\"vad_chunks_\" + str(i) + \".wav\")\n",
    "except:\n",
    "     print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc73c16",
   "metadata": {},
   "source": [
    "# htmlファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ff55197",
   "metadata": {},
   "outputs": [],
   "source": [
    "preS = '<!DOCTYPE html><html lang=\"ja\">'\n",
    "postS = '\\t</body>\\n</html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "dzs = open('diarization.txt').read().splitlines()\n",
    "\n",
    "groups = []\n",
    "g = []\n",
    "lastend = 0\n",
    "\n",
    "for d in dzs:   \n",
    "  if g and (g[0].split()[-1] != d.split()[-1]):      #same speaker\n",
    "    groups.append(g)\n",
    "    g = []\n",
    "  \n",
    "  g.append(d)\n",
    "  \n",
    "  end = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=d)[1]\n",
    "  end = millisec(end)\n",
    "  if (lastend > end):       #segment engulfed by a previous segment\n",
    "    groups.append(g)\n",
    "    g = [] \n",
    "  else:\n",
    "    lastend = end\n",
    "if g:\n",
    "  groups.append(g)\n",
    "print(*groups, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ca44ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = {'SPEAKER_00':('speaker0', '#CFF5E7', 'mint'), 'SPEAKER_01':('speaker1', '#A0E4CB', 'teal') ,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb288bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(preS)\n",
    "gidx = 0\n",
    "sapcer_datetime = datetime.timedelta(hours= 0,minutes=0,seconds=spacermilli/1000)\n",
    "for g in groups:  \n",
    "    shift = re.findall('[0-9]+:[0-9]+:[0-9]+\\.[0-9]+', string=g[0])[1]\n",
    "    end_time =datetime.timedelta(hours= float(shift[0:2]),minutes=float(shift[3:5]),seconds=float(shift[6:])) - sapcer_datetime #the start time in the original video\n",
    "    if subs[gidx]:\n",
    "        speaker = g[0].split()[-1]\n",
    "    if speaker in speakers:\n",
    "        speaker, boxclr, spkrclr = speakers[speaker] \n",
    "    if subs[gidx].start < end_time:\n",
    "        html.append(f'<div class=\"e\" style=\"background-color: {boxclr}\">\\n');\n",
    "        html.append(f'<span style=\"color: {spkrclr}\">{speaker}　　　　{subs[gidx].start}</span><br>\\n')\n",
    "    try:\n",
    "        while subs[gidx].start < end_time:\n",
    "          html.append(f'<div class=\"c\">')\n",
    "          html.append(f'\\t\\t\\t\\t<div class=\"t\"> {subs[gidx].content}</div><br>\\n')\n",
    "          html.append(f'</div>')\n",
    "          #print(speaker, boxclr, spkrclr,gidx,subs[gidx].content)\n",
    "          gidx += 1\n",
    "        html.append(f'</div>\\n');\n",
    "    except IndexError:\n",
    "        html.append(f'</div>\\n');\n",
    "        break\n",
    "\n",
    "html.append(postS)\n",
    "s = \"\".join(html)\n",
    "\n",
    "with open(target_id+\"_capspeaker.html\", \"w\") as text_file:\n",
    "    text_file.write(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
